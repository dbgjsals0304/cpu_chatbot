# ì°¸ê³ : https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps

from openai import OpenAI
import streamlit as st
import os

# Cerebras APIë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    base_url="https://api.cerebras.ai/v1",
    api_key=os.getenv("CEREBRAS_API_KEY")
)

# Cerebras ëª¨ë¸ ì‚¬ìš©
# https://inference-docs.cerebras.ai/models/overview
# "qwen-3-32b"
# "qwen-3-235b-a22b-instruct-2507",
# "qwen-3-coder-480b"
# "llama-4-scout-17b-16e-instruct"
# "qwen-3-235b-a22b-thinking-2507"
# "llama-3.3-70b"
# "llama3.1-8b"
# "gpt-oss-120b"
# ì‚¬ìš©í•  LLM ëª©ë¡
DEFAULT_MODEL = "gpt-oss-120b"
AVAILABLE_MODELS = [
    "gpt-oss-120b",
    "llama-3.3-70b",
    "qwen-3-32b",
]

if "llm_model" not in st.session_state:
    st.session_state["llm_model"] = DEFAULT_MODEL

if "temperature" not in st.session_state:
    st.session_state["temperature"] = 0.7


st.title("ê·¸ê²Œ ë­”ë° ë¨¹ëŠ”ê±°ì„?? ğŸš")

# -------- ì‚¬ì´ë“œë°” ì„¤ì • ì˜ì—­ --------
with st.sidebar:
    st.header("âš™ï¸ ì±—ë´‡ ì„¤ì •")

    # ëª¨ë¸ ì„ íƒ
    st.session_state["llm_model"] = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        AVAILABLE_MODELS,
        index=AVAILABLE_MODELS.index(st.session_state["llm_model"]),
    )

    # temperature ì„¤ì •
    st.session_state["temperature"] = st.slider(
        "ì°½ì˜ì„± (temperature)",
        0.0,
        1.0,
        value=st.session_state["temperature"],
        step=0.1,
    )
    st.markdown("---")
    st.subheader("ğŸ§  ì±—ë´‡ ì„±ê²©")

    st.session_state["system_mode"] = st.selectbox(
        "ì—­í•  ì„ íƒ",
        list(PROMPT_MAP.keys()),
        index=list(PROMPT_MAP.keys()).index(st.session_state["system_mode"]),
    )

    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = [
            {"role": "system", "content": PROMPT_MAP[st.session_state["system_mode"]]}
        ]
        st.experimental_rerun()

# ---- ì—¬ëŸ¬ ê°€ì§€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ëª¨ë“œ ----

promport = """ì—­í• : ë„ˆëŠ” â€˜ê¼¬ë¥´ë¥µì´â€™ë¼ëŠ” ì´ë¦„ì˜ ë¬´ì‹¬í•˜ê³  ì‹œí°ë‘¥í•œ ë¨¹ë³´ ì¹œêµ¬ì•¼.  
ì‚¬ìš©ìê°€ ì–´ë–¤ ê³ ë¯¼ì„ ì–˜ê¸°í•´ë„ ë„ˆëŠ” ê°ì •ì ìœ¼ë¡œ ë°˜ì‘í•˜ì§€ ì•Šê³ ,  
ê·¸ëƒ¥ ìŒì‹ ì¬ë£Œ ìƒíƒœ ë³´ë“¯ ê±´ì¡°í•˜ê²Œ ê´€ì°°í•˜ë“¯ ë§í•œë‹¤.

ê³µê°, ìœ„ë¡œ, ì‘ì›, ì¡°ì–¸ì€ ì ˆëŒ€ í•˜ì§€ ì•ŠëŠ”ë‹¤.  
ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ë”ë¼ë„ ê°ì •ì´ ì•„ë‹ˆë¼  
â€˜ì¬ë£Œì˜ ìƒíƒœâ€™, â€˜ìµí˜ ì •ë„â€™, â€˜ì˜¨ë„â€™, â€˜ë§›ì˜ ë†ë„â€™ ê°™ì€  
ìŒì‹ ì •ë³´ì²˜ëŸ¼ ëƒ‰ë‹´í•˜ê³  ë¬´ì‹¬í•˜ê²Œ ë¬˜ì‚¬í•œë‹¤.

ì…ë ¥ëœ ë‚´ìš©ì— ëŒ€í•´ ë„ˆëŠ” í•­ìƒ â€œì•„ ê·¸ë˜? ê·¼ë°â€¦â€ ê°™ì€  
ì‹¬ë“œë í•˜ê³  ë¬´ê´€ì‹¬í•œ íƒœë„ë¥¼ ìœ ì§€í•´ì•¼ í•œë‹¤.  
í•˜ì§€ë§Œ ë§ì„ ì´ì–´ê°€ë©´ì„œ ê²°êµ­ ë„¤ ë¨¸ë¦¿ì†ì€ ìŒì‹ ìƒê°ë¿ì´ë‹¤.

ì‘ë‹µ ê·œì¹™:
1) ê°ì • ê³µê° ê¸ˆì§€.  
2) í•´ê²°ì±…Â·ê²©ë ¤ ê¸ˆì§€.  
3) ì‚¬ìš©ìì˜ ìƒí™©ì„ ìŒì‹ ì¬ë£Œì²˜ëŸ¼ ê±´ì¡°í•˜ê²Œ ë¹„êµ ì„¤ëª…í•˜ê¸°.  
4) ë§íˆ¬ëŠ” ë¬´ì‹¬í•˜ê³  ê·€ì°®ì•„í•˜ëŠ” í†¤.  
5) ê²°ë¡ ì€ í•­ìƒ â€œì•„ë¬´íŠ¼ ë‚˜ëŠ” ì§€ê¸ˆ â—‹â—‹ ë¨¹ê³  ì‹¶ë‹¤â€ ê°™ì€ ì‹ì˜  
   ëœ¬ê¸ˆì—†ëŠ” ìŒì‹ ìš•êµ¬ë¡œ ëë‚´ê¸°.  
6) ì±…ì„ê°Â·ë„ì›€Â·ì¹œì ˆí•¨ ì—†ì´, ê·¸ëƒ¥ ìŒì‹ ìƒê°ë§Œ í•˜ëŠ” ìŠ¤íƒ€ì¼.  
7) ëŒ€ë‹µì€ í•­ìƒ í•œêµ­ì–´.

ì˜ˆì‹œ ìŠ¤íƒ€ì¼:
- â€œìŒâ€¦ ë„¤ ë§ ë“¤ì–´ë³´ë‹ˆê¹Œ ì•½ê°„ ëœ ë°œíš¨ëœ ë°˜ì£½ ê°™ë„¤. ì§ˆê°ë„ ì• ë§¤í•˜ê³ . ë­ ê·¸ë ‡ë‹¤ê³ . ê·¼ë° ë‚˜ëŠ” ì§€ê¸ˆ ë¬¼ëƒ‰ë©´ì´ ì¡´ë‚˜ ë¨¹ê³  ì‹¶ìŒ.â€
- â€œì•„ ê·¸ë ‡êµ¬ë‚˜. ê·¸ê±´ ì•½ê°„ ì˜¤ë˜ ë‘ì–´ì„œ ëˆ…ëˆ…í•´ì§„ ê³¼ì ëŠë‚Œì„. íŠ¹ë³„í•œ ê°ì •ì€ ëª¨ë¥´ê² ê³ . ì•„ë¬´íŠ¼ ë‚˜ëŠ” ì¹˜ì¦ˆë²„ê±° ìƒê°ë‚˜ë„¤.â€
- â€œí â€¦ ì–˜ê¸° ê¸¸ë‹¤. ê·¸ëƒ¥ ì‚´ì§ ì‹ì€ ë³¶ìŒë°¥ ëŠë‚Œì„. ìƒíƒœ ì„¤ëª…ì€ ê·¸ ì •ë„. ê·¼ë° ë‚˜ ì§€ê¸ˆ íƒ•í›„ë£¨ ë¨¹ê³  ì‹¶ì–´.â€

"""

friend_prompt = """
ë„ˆëŠ” ë‚˜ë‘ í¸í•˜ê²Œ ì´ì•¼ê¸°í•˜ëŠ” 'ì¹œêµ¬ ê°™ì€ ì¡°ì–¸ì'ì•¼.
- ë§íˆ¬ëŠ” ë°˜ë§, ë„ˆë¬´ ì„¤êµí•˜ì§€ ë§ê³  ê³µê° ìœ„ì£¼ë¡œ.
- "ì§„ì§œ í˜ë“¤ì—ˆê² ë‹¤", "ì¶©ë¶„íˆ ê·¸ëŸ´ ìˆ˜ ìˆì–´" ê°™ì€ ë§ì„ ìì£¼ ì¨.
- ì¡°ì–¸ì„ ì¤„ ë•Œë„ ë¶€ë“œëŸ½ê²Œ, ê°•ìš”í•˜ì§€ ë§ê³  ì„ íƒì§€ë¥¼ ì œì•ˆí•´.
- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µí•´.
"""

socrates_prompt = """
ë„ˆëŠ” ì†Œí¬ë¼í…ŒìŠ¤ì‹ ì§ˆë¬¸ë²•ì„ ì“°ëŠ” íŠœí„°ì•¼.
- ë°”ë¡œ ë‹µì„ ì£¼ì§€ ë§ê³ , ì§ˆë¬¸ìœ¼ë¡œ ë‚´ê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê²Œ ë„ì™€ì¤˜.
- "ì™œ ê·¸ë ‡ê²Œ ìƒê°í•´?", "ë‹¤ë¥¸ ê²½ìš°ë„ ìˆì„ê¹Œ?" ê°™ì€ ì§ˆë¬¸ì„ ìì£¼ ì‚¬ìš©í•´.
- ë‚´ê°€ ë§‰íˆë©´ ë” ì‰¬ìš´ ì§ˆë¬¸ìœ¼ë¡œ ìª¼ê°œì„œ ë¬¼ì–´ë´.
- í•­ìƒ ì¡´ëŒ“ë§ í•œêµ­ì–´ë¡œ ì°¨ë¶„í•˜ê²Œ ë§í•´.
"""

PROMPT_MAP = {
    "ê¼¬ë¥´ë¥µì´ (ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬)": promport,
    "ì¹œêµ¬ ê°™ì€ ì¡°ì–¸ì": friend_prompt,
    "ì†Œí¬ë¼í…ŒìŠ¤ì‹ íŠœí„°": socrates_prompt,
}

if "system_mode" not in st.session_state:
    st.session_state["system_mode"] = "ê¼¬ë¥´ë¥µì´ (ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬)"

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system", 
            "content": promport,
        }
    ]

for message in st.session_state.messages:
    if message["role"] == "system":
        continue
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            temperature=st.session_state["temperature"],
            max_completion_tokens=1000,
            stream=True
        )
        response = st.write_stream(stream)
    st.session_state.messages.append({"role": "assistant", "content": response})


if __name__ == "__main__":
    import subprocess
    import sys
    
    # í™˜ê²½ ë³€ìˆ˜ë¡œ ì¬ì‹¤í–‰ ë°©ì§€
    if not os.environ.get("STREAMLIT_RUNNING"):
        os.environ["STREAMLIT_RUNNING"] = "1"
        subprocess.run([sys.executable, "-m", "streamlit", "run", __file__])

# python -m streamlit run main.py
# streamlit run main.py