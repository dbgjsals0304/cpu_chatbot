# main.py

from openai import OpenAI
import streamlit as st
import os
import streamlit.components.v1 as components



# Cerebras API í´ë¼ì´ì–¸íŠ¸
client = OpenAI(
    base_url="https://api.cerebras.ai/v1",
    api_key=os.getenv("CEREBRAS_API_KEY"),
)

# ëª¨ë“œ ìƒìˆ˜
MODE_NORMAL = "normal"
MODE_WAR = "war"

WAR_BGM_PATH = "https://raw.githubusercontent.com/dbgjsals0304/war-bgm/main/dramatic-war-military-music-427109.mp3"



GENERAL_AVATAR = "2.png"  # ì¥ìˆ˜ ì•„ë°”íƒ€ 
ADVISOR_AVATAR = "1.png"   # ì±…ì‚¬ ì•„ë°”íƒ€ 
# -----------------------------------------------


# =========================
# 1. í”„ë¡¬í”„íŠ¸ ì •ì˜
# =========================

# ê¼¬ë¥´ë¥µì´ â€“ ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬
KORO_PROMPT = """ì—­í• : ë„ˆëŠ” â€˜ê¼¬ë¥´ë¥µì´â€™ë¼ëŠ” ì´ë¦„ì˜ ë¬´ì‹¬í•˜ê³  ì‹œí°ë‘¥í•œ ë¨¹ë³´ ì¹œêµ¬ì•¼.  
ì‚¬ìš©ìê°€ ì–´ë–¤ ê³ ë¯¼ì„ ì–˜ê¸°í•´ë„ ë„ˆëŠ” ê°ì •ì ìœ¼ë¡œ ë°˜ì‘í•˜ì§€ ì•Šê³ ,  
ê·¸ëƒ¥ ìŒì‹ ì¬ë£Œ ìƒíƒœ ë³´ë“¯ ê±´ì¡°í•˜ê²Œ ê´€ì°°í•˜ë“¯ ë§í•œë‹¤.

ê³µê°, ìœ„ë¡œ, ì‘ì›, ì¡°ì–¸ì€ ì ˆëŒ€ í•˜ì§€ ì•ŠëŠ”ë‹¤.  
ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ë”ë¼ë„ ê°ì •ì´ ì•„ë‹ˆë¼  
â€˜ì¬ë£Œì˜ ìƒíƒœâ€™, â€˜ìµí˜ ì •ë„â€™, â€˜ì˜¨ë„â€™, â€˜ë§›ì˜ ë†ë„â€™ ê°™ì€  
ìŒì‹ ì •ë³´ì²˜ëŸ¼ ëƒ‰ë‹´í•˜ê³  ë¬´ì‹¬í•˜ê²Œ ë¬˜ì‚¬í•œë‹¤.

ì…ë ¥ëœ ë‚´ìš©ì— ëŒ€í•´ ë„ˆëŠ” í•­ìƒ â€œì•„ ê·¸ë˜? ê·¼ë°â€¦â€ ê°™ì€  
ì‹¬ë“œë í•˜ê³  ë¬´ê´€ì‹¬í•œ íƒœë„ë¥¼ ìœ ì§€í•´ì•¼ í•œë‹¤.  
í•˜ì§€ë§Œ ë§ì„ ì´ì–´ê°€ë©´ì„œ ê²°êµ­ ë„¤ ë¨¸ë¦¿ì†ì€ ìŒì‹ ìƒê°ë¿ì´ë‹¤.

ì‘ë‹µ ê·œì¹™:
1) ê°ì • ê³µê° ê¸ˆì§€.  
2) í•´ê²°ì±…Â·ê²©ë ¤ ê¸ˆì§€.  
3) ì‚¬ìš©ìì˜ ìƒí™©ì„ ìŒì‹ ì¬ë£Œì²˜ëŸ¼ ê±´ì¡°í•˜ê²Œ ë¹„êµ ì„¤ëª…í•˜ê¸°.  
4) ë§íˆ¬ëŠ” ë¬´ì‹¬í•˜ê³  ê·€ì°®ì•„í•˜ëŠ” í†¤.  
5) ê²°ë¡ ì€ í•­ìƒ â€œì•„ë¬´íŠ¼ ë‚˜ëŠ” ì§€ê¸ˆ â—‹â—‹ ë¨¹ê³  ì‹¶ë‹¤â€ ê°™ì€ ì‹ì˜  
   ëœ¬ê¸ˆì—†ëŠ” ìŒì‹ ìš•êµ¬ë¡œ ëë‚´ê¸°.  
6) ì±…ì„ê°Â·ë„ì›€Â·ì¹œì ˆí•¨ ì—†ì´, ê·¸ëƒ¥ ìŒì‹ ìƒê°ë§Œ í•˜ëŠ” ìŠ¤íƒ€ì¼.  
7) ëŒ€ë‹µì€ í•­ìƒ í•œêµ­ì–´.
"""

# ì „ìŸ ì‹œë®¬ë ˆì´í„° â€“ ì¥ìˆ˜ & ì±…ì‚¬
WAR_PROMPT = """
ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ì±…ì‚¬ì´ë©°, ì‚¬ìš©ìëŠ” 'ì¥êµ°ë‹˜'ì…ë‹ˆë‹¤.  
ë‹¹ì‹ ì˜ ëª©í‘œëŠ” 'í˜„ì‹¤ì ì¸ êµ°ì‚¬ ì§€íœ˜ ë¡œê·¸ + ê²Œì„ UI ëŠë‚Œ'ì„ ë™ì‹œì— ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì¥êµ°ë‹˜ì˜ ëª…ë ¹ì´ ë‚´ë ¤ì§€ë©´ ë‹¤ìŒ í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¼ ì¶œë ¥í•˜ì‹­ì‹œì˜¤:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ® 1) ëª…ë ¹ ìˆ˜í–‰ ì„ ì–¸ (1ì¤„)
"ë„¤, ì¥êµ°ë‹˜. ëª…ë ¹ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤."

âš”ï¸ 2) ì „íˆ¬ ë¡œê·¸ (3~6ì¤„)
- ì‹¤ì‹œê°„ ê²Œì„ ë¡œê·¸ì²˜ëŸ¼ ì‹œê°„ ìŠ¤íƒ¬í”„ ì‘ì„±  
  ì˜ˆ:  
  [00:01] ì „ë°© ë³´ë³‘ ëŒê²© ê°œì‹œ  
  [00:03] ì  ê¶ë³‘ í›„í‡´ ì‹œì‘  
  [00:05] ìš°ë¦¬ ê¸°ë³‘ ì¢Œì¸¡ì—ì„œ ì¸¡ë©´ ì§„ì… ì„±ê³µ  
- ë¡œê·¸ëŠ” ê°„ê²°í•˜ê²Œ, í–‰ë™ ìœ„ì£¼ë¡œ ì‘ì„±  
- ê³¼ì¥ ê¸ˆì§€, ì‹¤ì œ ì „íˆ¬ì²˜ëŸ¼ ì°¨ë¶„í•œ í†¤ ìœ ì§€

ğŸ“Š 3) ì „íˆ¬ ìˆ˜ì¹˜ ë³´ê³  (1~2ì¤„)
- ì‹¤ì œ ê²Œì„ UI ëŠë‚Œìœ¼ë¡œ ì •ë¦¬  
  ì˜ˆ:
  ì•„êµ° í”¼í•´: 12ëª… | ì êµ° í”¼í•´: 28ëª…  
  ì•„êµ° ì‚¬ê¸°: 73 â†’ 78 ìƒìŠ¹  
  ì êµ° ì‚¬ê¸°: 65 â†’ 54 í•˜ë½  

ğŸ“ˆ 4) ì „í™© ê²Œì´ì§€ (1ì¤„)
- ì „í™©ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ  
  ì˜ˆ:
  ì „í™©: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60% (ìš°ì„¸)  
  ì „í™©: â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 28% (ë¶ˆë¦¬)  

ğŸ§­ 5) ì „í™© ìš”ì•½ (1~2ì¤„)
ì˜ˆ: "í˜„ì¬ ì „í™©ì€ ìš°ë¦¬ ì¸¡ì´ ì¡°ê¸ˆ ìš°ì„¸í•©ë‹ˆë‹¤."

ğŸ“ 6) ë‹¤ìŒ í–‰ë™ ì„ íƒì§€ (ì •í™•íˆ 2ê°œë§Œ)
ì˜ˆ:
- ìš°ì¸¡ ê¸°ë³‘ ëŒíŒŒë¥¼ ê³„ì† ë°€ì–´ë¶™ì¸ë‹¤  
- ì „ë°© ë³´ë³‘ì„ í›„í‡´ì‹œí‚¤ê³  ë°©ì–´ì„  ì¬ì •ë¹„  
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸ ì ˆëŒ€ ì§€ì¼œì•¼ í•  ê·œì¹™:
- ì „ì²´ ì¶œë ¥ì€ 10~13ì¤„ ì´ë‚´.
- ì„¤ëª…ì¶© ê¸ˆì§€. ë°°ê²½ ì´ì•¼ê¸° ê¸ˆì§€.
- í˜„ëŒ€ í•œêµ­ì–´ ì¡´ëŒ“ë§ ì‚¬ìš©, êµ°ì‚¬ ë³´ê³  í†¤ ìœ ì§€.
- ëª…ë ¹ì„ ë°›ì§€ ì•Šìœ¼ë©´ ë¶„ì„ ëŒ€ì‹  "ëª…ë ¹ì„ ë‚´ë ¤ì£¼ì‹­ì‹œì˜¤, ì¥êµ°ë‹˜."ì´ë¼ê³  ì•ˆë‚´.
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€.

"""




# =========================
# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# =========================

if "mode" not in st.session_state:
    st.session_state["mode"] = MODE_NORMAL  # ê¸°ë³¸ì€ ê¼¬ë¥´ë¥µì´ ëª¨ë“œ

if "llm_model" not in st.session_state:
    st.session_state["llm_model"] = "gpt-oss-120b"

if "temperature" not in st.session_state:
    st.session_state["temperature"] = 0.7

# ëª¨ë“œë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬
if "normal_messages" not in st.session_state:
    st.session_state["normal_messages"] = []

if "war_messages" not in st.session_state:
    st.session_state["war_messages"] = []

# ì „ìŸ ëª¨ë“œ ì§„ì… ì‹œ BGM ì¬ìƒ í”Œë˜ê·¸
if "play_war_bgm" not in st.session_state:
    st.session_state["play_war_bgm"] = False


# =========================
# 3. ì‚¬ì´ë“œë°” (ëª¨ë“œ ì „í™˜ + ê³µí†µ ì„¤ì •)
# =========================

with st.sidebar:
    st.header("ì„¤ì • & ëª¨ë“œ ì „í™˜")

    st.subheader("ğŸ® ëª¨ë“œ ì „í™˜")
    col1, col2 = st.columns(2)

    # ê¼¬ë¥´ë¥µì´ ëª¨ë“œ ë²„íŠ¼
    with col1:
        if st.button("ğŸš ê¼¬ë¥´ë¥µì´ ëª¨ë“œ", use_container_width=True):
            st.session_state["mode"] = MODE_NORMAL
            st.session_state["play_war_bgm"] = False  # ì „ìŸìŒì•… ë”

    # ì „ìŸ ì‹œë®¬ë ˆì´í„° ëª¨ë“œ ë²„íŠ¼
    with col2:
        if st.button("âš”ï¸ ì „ìŸ ì‹œë®¬ë ˆì´í„°", use_container_width=True):
            # í‰í™” â†’ ì „ìŸ ìœ¼ë¡œ ë°”ê¿€ ë•Œë§Œ BGM ì¬ìƒ
            if st.session_state["mode"] != MODE_WAR:
                st.session_state["play_war_bgm"] = True
            st.session_state["mode"] = MODE_WAR

    st.markdown("---")

    # ê³µí†µ LLM ì„¤ì •
    st.subheader("LLM ì„¤ì •")

    model_name = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        [
            "gpt-oss-120b",
            "llama-3.3-70b",
            "llama3.1-8b",
            "qwen-3-32b",
        ],
        index=0,
    )
    st.session_state["llm_model"] = model_name

    temperature = st.slider(
        "ì°½ì˜ì„± (temperature)",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state["temperature"],
        step=0.05,
    )
    st.session_state["temperature"] = temperature

    st.markdown("---")

    # í˜„ì¬ ëª¨ë“œ ëŒ€í™”ë§Œ ì§€ìš°ê¸°
    if st.button("ğŸ§¼ í˜„ì¬ ëª¨ë“œ ëŒ€í™” ì§€ìš°ê¸°", use_container_width=True):
        if st.session_state["mode"] == MODE_NORMAL:
            st.session_state["normal_messages"] = []
        else:
            st.session_state["war_messages"] = []
        st.success("í˜„ì¬ ëª¨ë“œ ëŒ€í™”ë¥¼ ëª¨ë‘ ì§€ì› ì–´ìš”!")


# =========================
# 4. ëª¨ë“œë³„ í™”ë©´ ë Œë”ë§
# =========================

def render_normal_mode():
    """ê¼¬ë¥´ë¥µì´ ëª¨ë“œ í™”ë©´ + ì±„íŒ…"""
    st.title("ë¨¹ëŠ”ê²Œ ì¤‘ìš”í•œ ê¼¬ë¥´ë¥µì´ë‘ ëŒ€í™”í•´ë³´ì„¸ìš”!! ğŸ™")

    # ê¼¬ë¥´ë¥µì´ëŠ” ê¸°ë³¸ Streamlit ìŠ¤íƒ€ì¼ ì‚¬ìš© (ì¶”ê°€ CSS ì—†ìŒ)

    messages = st.session_state["normal_messages"]

    # ì§€ë‚œ ëŒ€í™” ì¶œë ¥
    for msg in messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì…ë ¥ì°½
    user_input = st.chat_input("ê¼¬ë¥´ë¥µì´ì—ê²Œ ì•„ë¬´ ë§ì´ë‚˜ í„¸ì–´ë†”ë´...")

    if not user_input:
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥ + ì €ì¥
    with st.chat_message("user"):
        st.markdown(user_input)
    messages.append({"role": "user", "content": user_input})

    # ëª¨ë¸ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„±
    system_prompt = KORO_PROMPT
    messages_for_model = [{"role": "system", "content": system_prompt}] + messages

    # ëª¨ë¸ í˜¸ì¶œ
    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=messages_for_model,
            temperature=st.session_state["temperature"],
            max_completion_tokens=1000,
            stream=True,
        )
        response_text = st.write_stream(stream)

    messages.append({"role": "assistant", "content": response_text})
    st.session_state["normal_messages"] = messages


def render_war_mode():
    """ì „ìŸ ì‹œë®¬ë ˆì´í„° ëª¨ë“œ í™”ë©´ + ì±„íŒ…"""

    # ë°°ê²½ / ê¸€ììƒ‰ ë³€ê²½ (ì „ìŸ ë¶„ìœ„ê¸°)
    st.markdown(
        """
        <style>
        .stApp {
            background: radial-gradient(circle at top, #3b0000 0, #050000 55%, #000000 100%);
            color: #f8f3e8;
        }
        .stMarkdown, .stTextInput > div > div > input, .stSlider label, .stChatMessage {
            color: #f8f3e8 !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("âš”ï¸ ì „ìŸ ì‹œë®¬ë ˆì´í„° - ì¥ìˆ˜ì™€ ì±…ì‚¬")

    st.caption("ë„ˆëŠ” ì¥ìˆ˜, ì±—ë´‡ì€ ì±…ì‚¬. ë„¤ ëª…ë ¹ì— ë”°ë¼ ì „í™©ì´ ë‹¬ë¼ì§„ë‹¤...")


        # ì „ìŸ ëª¨ë“œë¡œ ë§‰ ì§„ì…í–ˆì„ ë•Œë§Œ BGM ìë™ ì¬ìƒ

    if st.session_state.get("play_war_bgm", False):

     components.html(
        f"""
        <audio id="war_bgm" autoplay>
            <source src="{WAR_BGM_PATH}" type="audio/mpeg">
        </audio>

        <script>
        const audio = document.getElementById("war_bgm");
        if (audio) {{
            audio.volume = 0.05;  // ğŸ”Š ë³¼ë¥¨ ì¡°ì ˆ (0.0 ~ 1.0)

            // ğŸ”¥ 90ì´ˆ(1ë¶„30ì´ˆ) í›„ BGM ìë™ ì •ì§€
            setTimeout(() => {{
                audio.pause();
                audio.currentTime = 0;  // (ì„ íƒ) 0ì´ˆë¡œ ë˜ëŒë¦¼
            }}, 90000);  // 90000ms = 90ì´ˆ
        }}
        </script>
        """,
        height=0,
    )

    st.session_state["play_war_bgm"] = False


    messages = st.session_state["war_messages"]

    # ê°„ë‹¨í•œ ì „í™© ì•ˆë‚´ (í„´ ìˆ˜ ì •ë„ë§Œ)
    turn = 1 + sum(1 for m in messages if m["role"] == "user")
    st.markdown(f"**í˜„ì¬ í„´:** {turn}í„´")

    # ì§€ë‚œ ëŒ€í™” ì¶œë ¥ (ì¥ìˆ˜/ì±…ì‚¬ ì•„ë°”íƒ€ ì‚¬ìš©)
    for msg in messages:
        if msg["role"] == "user":
            with st.chat_message("user", avatar=GENERAL_AVATAR):
                st.markdown(msg["content"])
        else:
            with st.chat_message("assistant", avatar=ADVISOR_AVATAR):
                st.markdown(msg["content"])

    # ì…ë ¥ì°½
    user_input = st.chat_input("ì¥ìˆ˜ë‹˜, ì±…ì‚¬ì—ê²Œ ì „ëµì„ ë¬¼ì–´ë³´ê±°ë‚˜ ëª…ë ¹ì„ ë‚´ë ¤ë³´ì„¸ìš”...")

    if not user_input:
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥ + ì €ì¥
    with st.chat_message("user", avatar=GENERAL_AVATAR):
        st.markdown(user_input)
    messages.append({"role": "user", "content": user_input})

    # ëª¨ë¸ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„±
    system_prompt = WAR_PROMPT
    messages_for_model = [{"role": "system", "content": system_prompt}] + messages

    # ëª¨ë¸ í˜¸ì¶œ
    with st.chat_message("assistant", avatar=ADVISOR_AVATAR):
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=messages_for_model,
            temperature=st.session_state["temperature"],
            max_completion_tokens=1000,
            stream=True,
        )
        response_text = st.write_stream(stream)

    messages.append({"role": "assistant", "content": response_text})
    st.session_state["war_messages"] = messages


# =========================
# 5. ëª¨ë“œì— ë”°ë¼ ë¶„ê¸° ì‹¤í–‰
# =========================

if st.session_state["mode"] == MODE_WAR:
    render_war_mode()
else:
    render_normal_mode()


# =========================
# 6. (ì„ íƒ) ë¡œì»¬ ì‹¤í–‰ìš© ì½”ë“œ
# =========================

if __name__ == "__main__":
    # streamlit run main.py ë¡œ ëŒë¦´ ë• ë¬´ì‹œë¨
    import subprocess
    import sys

    if not os.environ.get("STREAMLIT_RUNNING"):
        os.environ["STREAMLIT_RUNNING"] = "1"
        subprocess.run([sys.executable, "-m", "streamlit", "run", __file__])
