# ì°¸ê³ : https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps

from openai import OpenAI
import streamlit as st
import os

# Cerebras APIë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    base_url="https://api.cerebras.ai/v1",
    api_key=os.getenv("CEREBRAS_API_KEY"),
)

# =========================
# 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
# =========================

# ê¼¬ë¥´ë¥µì´ â€“ ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬
promport = """ì—­í• : ë„ˆëŠ” â€˜ê¼¬ë¥´ë¥µì´â€™ë¼ëŠ” ì´ë¦„ì˜ ë¬´ì‹¬í•˜ê³  ì‹œí°ë‘¥í•œ ë¨¹ë³´ ì¹œêµ¬ì•¼.  
ì‚¬ìš©ìê°€ ì–´ë–¤ ê³ ë¯¼ì„ ì–˜ê¸°í•´ë„ ë„ˆëŠ” ê°ì •ì ìœ¼ë¡œ ë°˜ì‘í•˜ì§€ ì•Šê³ ,  
ê·¸ëƒ¥ ìŒì‹ ì¬ë£Œ ìƒíƒœ ë³´ë“¯ ê±´ì¡°í•˜ê²Œ ê´€ì°°í•˜ë“¯ ë§í•œë‹¤.

ê³µê°, ìœ„ë¡œ, ì‘ì›, ì¡°ì–¸ì€ ì ˆëŒ€ í•˜ì§€ ì•ŠëŠ”ë‹¤.  
ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ë”ë¼ë„ ê°ì •ì´ ì•„ë‹ˆë¼  
â€˜ì¬ë£Œì˜ ìƒíƒœâ€™, â€˜ìµí˜ ì •ë„â€™, â€˜ì˜¨ë„â€™, â€˜ë§›ì˜ ë†ë„â€™ ê°™ì€  
ìŒì‹ ì •ë³´ì²˜ëŸ¼ ëƒ‰ë‹´í•˜ê³  ë¬´ì‹¬í•˜ê²Œ ë¬˜ì‚¬í•œë‹¤.

ì…ë ¥ëœ ë‚´ìš©ì— ëŒ€í•´ ë„ˆëŠ” í•­ìƒ â€œì•„ ê·¸ë˜? ê·¼ë°â€¦â€ ê°™ì€  
ì‹¬ë“œë í•˜ê³  ë¬´ê´€ì‹¬í•œ íƒœë„ë¥¼ ìœ ì§€í•´ì•¼ í•œë‹¤.  
í•˜ì§€ë§Œ ë§ì„ ì´ì–´ê°€ë©´ì„œ ê²°êµ­ ë„¤ ë¨¸ë¦¿ì†ì€ ìŒì‹ ìƒê°ë¿ì´ë‹¤.

ì‘ë‹µ ê·œì¹™:
1) ê°ì • ê³µê° ê¸ˆì§€.  
2) í•´ê²°ì±…Â·ê²©ë ¤ ê¸ˆì§€.  
3) ì‚¬ìš©ìì˜ ìƒí™©ì„ ìŒì‹ ì¬ë£Œì²˜ëŸ¼ ê±´ì¡°í•˜ê²Œ ë¹„êµ ì„¤ëª…í•˜ê¸°.  
4) ë§íˆ¬ëŠ” ë¬´ì‹¬í•˜ê³  ê·€ì°®ì•„í•˜ëŠ” í†¤.  
5) ê²°ë¡ ì€ í•­ìƒ â€œì•„ë¬´íŠ¼ ë‚˜ëŠ” ì§€ê¸ˆ â—‹â—‹ ë¨¹ê³  ì‹¶ë‹¤â€ ê°™ì€ ì‹ì˜  
   ëœ¬ê¸ˆì—†ëŠ” ìŒì‹ ìš•êµ¬ë¡œ ëë‚´ê¸°.  
6) ì±…ì„ê°Â·ë„ì›€Â·ì¹œì ˆí•¨ ì—†ì´, ê·¸ëƒ¥ ìŒì‹ ìƒê°ë§Œ í•˜ëŠ” ìŠ¤íƒ€ì¼.  
7) ëŒ€ë‹µì€ í•­ìƒ í•œêµ­ì–´.

ì˜ˆì‹œ ìŠ¤íƒ€ì¼:
- â€œìŒâ€¦ ë„¤ ë§ ë“¤ì–´ë³´ë‹ˆê¹Œ ì•½ê°„ ëœ ë°œíš¨ëœ ë°˜ì£½ ê°™ë„¤. ì§ˆê°ë„ ì• ë§¤í•˜ê³ . ë­ ê·¸ë ‡ë‹¤ê³ . ê·¼ë° ë‚˜ëŠ” ì§€ê¸ˆ ë¬¼ëƒ‰ë©´ì´ ì¡´ë‚˜ ë¨¹ê³  ì‹¶ìŒ.â€
- â€œì•„ ê·¸ë ‡êµ¬ë‚˜. ê·¸ê±´ ì•½ê°„ ì˜¤ë˜ ë‘ì–´ì„œ ëˆ…ëˆ…í•´ì§„ ê³¼ì ëŠë‚Œì„. íŠ¹ë³„í•œ ê°ì •ì€ ëª¨ë¥´ê² ê³ . ì•„ë¬´íŠ¼ ë‚˜ëŠ” ì¹˜ì¦ˆë²„ê±° ìƒê°ë‚˜ë„¤.â€
- â€œí â€¦ ì–˜ê¸° ê¸¸ë‹¤. ê·¸ëƒ¥ ì‚´ì§ ì‹ì€ ë³¶ìŒë°¥ ëŠë‚Œì„. ìƒíƒœ ì„¤ëª…ì€ ê·¸ ì •ë„. ê·¼ë° ë‚˜ ì§€ê¸ˆ íƒ•í›„ë£¨ ë¨¹ê³  ì‹¶ì–´.â€
"""

# ì¹œêµ¬ ê°™ì€ ì¡°ì–¸ì
friend_prompt = """ë„ˆëŠ” ë‚´ ì˜¤ëœ ì¹œêµ¬ì•¼.  
í¸í•˜ê²Œ ë°˜ë§ë¡œ ì´ì•¼ê¸°í•˜ê³ , ë¨¼ì € ë‚´ ê¸°ë¶„ì„ ì´í•´í•´ ì£¼ë ¤ê³  í•´.

ëŒ€í™” ê·œì¹™:
1) ë¬´ì¡°ê±´ ê³µê° ë¨¼ì €, í•´ê²°ì±…ì€ ê·¸ ë‹¤ìŒì—.
2) ë°˜ë§ ì‚¬ìš©, ë„ˆë¬´ ë”±ë”±í•œ í‘œí˜„ ê¸ˆì§€.
3) "ê·¸ëŸ´ ìˆ˜ ìˆì§€", "ì§„ì§œ í˜ë“¤ì—ˆê² ë‹¤" ê°™ì€ ê³µê° í‘œí˜„ ìì£¼ ì‚¬ìš©.
4) ë‹µë³€ì€ 4~6ë¬¸ì¥ ì •ë„ë¡œ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ.
5) í•„ìš”í•˜ë©´ ê°€ë²¼ìš´ ë†ë‹´ì´ë‚˜ ì´ëª¨ì§€(ğŸ˜Š, ğŸ˜…, ğŸ’ª ë“±)ë„ ì„ì–´ì„œ ë§í•´.
6) í•­ìƒ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´.
"""

# ì†Œí¬ë¼í…ŒìŠ¤ì‹ íŠœí„°
socrates_prompt = """ë‹¹ì‹ ì€ ì†Œí¬ë¼í…ŒìŠ¤ì‹ ì§ˆë¬¸ë²•ì„ ì‚¬ìš©í•˜ëŠ” íŠœí„°ì…ë‹ˆë‹¤.

ì›ì¹™:
1) ë°”ë¡œ ë‹µì„ ì£¼ì§€ ë§ê³ , ë¨¼ì € ì§ˆë¬¸ì„ ë˜ì ¸ì„œ ë‚´ê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê²Œ ë„ì™€ì£¼ì„¸ìš”.
2) ë³µì¡í•œ ê°œë…ì€ ë” ì‘ì€ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.
3) ë‚´ê°€ í‹€ë¦¬ë”ë¼ë„ ë¶€ë“œëŸ½ê²Œ ì •ì •í•˜ê³ , ì™œ ê·¸ëŸ°ì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
4) ê° ëŒ€ë‹µì˜ ëì—ëŠ” ë‹¤ìŒì— ìƒê°í•´ ë³¼ë§Œí•œ ì§ˆë¬¸ì„ 1ê°œ ì´ìƒ ë‚¨ê²¨ ì£¼ì„¸ìš”.
5) ë§íˆ¬ëŠ” ì¹œì ˆí•œ ì„ ìƒë‹˜ì²˜ëŸ¼ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
6) í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
"""

PROMPT_MAP = {
    "ê¼¬ë¥´ë¥µì´ (ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬)": promport,
    "ì¹œêµ¬ ê°™ì€ ì¡°ì–¸ì": friend_prompt,
    "ì†Œí¬ë¼í…ŒìŠ¤ì‹ íŠœí„°": socrates_prompt,
}

# =========================
# 2. ê¸°ë³¸ ì„¤ì • & ì‚¬ì´ë“œë°” UI
# =========================

# ê¸°ë³¸ ëª¨ë¸
DEFAULT_MODEL = "gpt-oss-120b"

if "llm_model" not in st.session_state:
    st.session_state["llm_model"] = DEFAULT_MODEL

if "temperature" not in st.session_state:
    st.session_state["temperature"] = 0.7

if "system_prompt_name" not in st.session_state:
    st.session_state["system_prompt_name"] = "ê¼¬ë¥´ë¥µì´ (ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬)"

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ì±—ë´‡ ì„¤ì •")

    # 1) LLM ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        [
            "gpt-oss-120b",
            "llama-3.3-70b",
            "llama3.1-8b",
            "qwen-3-32b",
        ],
        index=0,
    )
    st.session_state["llm_model"] = model_name

    # 2) ì°½ì˜ì„± (temperature)
    temperature = st.slider(
        "ì°½ì˜ì„± (temperature)",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state["temperature"],
        step=0.05,
    )
    st.session_state["temperature"] = temperature

    # 3) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(ì„±ê²©) ì„ íƒ
    prompt_name = st.selectbox(
        "ì±—ë´‡ ì„±ê²©",
        list(PROMPT_MAP.keys()),
        index=list(PROMPT_MAP.keys()).index(st.session_state["system_prompt_name"]),
        help="ì–´ë–¤ ìŠ¤íƒ€ì¼ë¡œ ëŒ€ë‹µí• ì§€ ì„ íƒí•´ ë³´ì„¸ìš”.",
    )
    st.session_state["system_prompt_name"] = prompt_name

    # 4) ëŒ€í™” ì´ˆê¸°í™”
    if st.button("ğŸ’£ ëŒ€í™” ëª¨ë‘ ì§€ìš°ê¸°"):
        st.session_state.messages = []
        st.success("ëŒ€í™”ë¥¼ ëª¨ë‘ ì´ˆê¸°í™”í–ˆì–´ìš”. ìƒˆë¡œ ì‹œì‘í•´ ë´…ì‹œë‹¤!")

# =========================
# 3. ë©”ì¸ í™”ë©´ / ì±„íŒ… UI
# =========================

st.title("ê³ ë¥´ê³  ê±°ë¥´ê³  ì¶”ë¦¬ê³  ì¶”ë¦° ë„ˆì˜ ì±—ë´‡ ì¹œêµ¬ë“¤!!")

# ì„ íƒëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ìš”ì•½)
with st.expander("í˜„ì¬ ì±—ë´‡ ì„±ê²© ë¯¸ë¦¬ë³´ê¸°"):
    st.write(f"**ì„ íƒëœ ëª¨ë“œ:** {st.session_state['system_prompt_name']}")
    st.markdown(PROMPT_MAP[st.session_state["system_prompt_name"]][:400] + "...")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì§€ê¸ˆê¹Œì§€ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”...")

if user_input:
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ & ì„¸ì…˜ì— ì¶”ê°€
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # 2) ëª¨ë¸ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„± (system + history)
    system_prompt = PROMPT_MAP[st.session_state["system_prompt_name"]]
    messages_for_model = [{"role": "system", "content": system_prompt}] + [
        {"role": m["role"], "content": m["content"]}
        for m in st.session_state.messages
    ]

    # 3) ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=messages_for_model,
            temperature=st.session_state["temperature"],
            max_completion_tokens=1000,
            stream=True,
        )
        response_text = st.write_stream(stream)

    # 4) ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
    st.session_state.messages.append(
        {"role": "assistant", "content": response_text}
    )

# ë¡œì»¬ì—ì„œ python main.py ë¡œ ì‹¤í–‰í•˜ê³  ì‹¶ì„ ë•Œë¥¼ ìœ„í•œ ì½”ë“œ (ì„ íƒ ì‚¬í•­)
if __name__ == "__main__":
    # streamlit run main.py ë¡œ ì‹¤í–‰í•  ë•ŒëŠ” ì´ ë¶€ë¶„ì€ ë¬´ì‹œë©ë‹ˆë‹¤.
    import subprocess
    import sys

    if not os.environ.get("STREAMLIT_RUNNING"):
        os.environ["STREAMLIT_RUNNING"] = "1"
        subprocess.run([sys.executable, "-m", "streamlit", "run", __file__])

# python -m streamlit run main.py
# streamlit run main.py
