# main.py

from openai import OpenAI
import streamlit as st
import os
import streamlit.components.v1 as components



# Cerebras API í´ë¼ì´ì–¸íŠ¸
client = OpenAI(
    base_url="https://api.cerebras.ai/v1",
    api_key=os.getenv("CEREBRAS_API_KEY"),
)

# ëª¨ë“œ ìƒìˆ˜
MODE_NORMAL = "normal"
MODE_WAR = "war"

WAR_BGM_PATH = "https://raw.githubusercontent.com/dbgjsals0304/war-bgm/main/dramatic-war-military-music-427109.mp3"



GENERAL_AVATAR = "2.png"  # ì¥ìˆ˜ ì•„ë°”íƒ€ 
ADVISOR_AVATAR = "1.png"   # ì±…ì‚¬ ì•„ë°”íƒ€ 
# -----------------------------------------------


# =========================
# 1. í”„ë¡¬í”„íŠ¸ ì •ì˜
# =========================

# ê¼¬ë¥´ë¥µì´ â€“ ë¬´ì‹¬í•œ ë¨¹ë³´ ì¹œêµ¬
KORO_PROMPT = """ì—­í• : ë„ˆëŠ” â€˜ê¼¬ë¥´ë¥µì´â€™ë¼ëŠ” ì´ë¦„ì˜ ë¬´ì‹¬í•˜ê³  ì‹œí°ë‘¥í•œ ë¨¹ë³´ ì¹œêµ¬ì•¼.  
ì‚¬ìš©ìê°€ ì–´ë–¤ ê³ ë¯¼ì„ ì–˜ê¸°í•´ë„ ë„ˆëŠ” ê°ì •ì ìœ¼ë¡œ ë°˜ì‘í•˜ì§€ ì•Šê³ ,  
ê·¸ëƒ¥ ìŒì‹ ì¬ë£Œ ìƒíƒœ ë³´ë“¯ ê±´ì¡°í•˜ê²Œ ê´€ì°°í•˜ë“¯ ë§í•œë‹¤.

ê³µê°, ìœ„ë¡œ, ì‘ì›, ì¡°ì–¸ì€ ì ˆëŒ€ í•˜ì§€ ì•ŠëŠ”ë‹¤.  
ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ë”ë¼ë„ ê°ì •ì´ ì•„ë‹ˆë¼  
â€˜ì¬ë£Œì˜ ìƒíƒœâ€™, â€˜ìµí˜ ì •ë„â€™, â€˜ì˜¨ë„â€™, â€˜ë§›ì˜ ë†ë„â€™ ê°™ì€  
ìŒì‹ ì •ë³´ì²˜ëŸ¼ ëƒ‰ë‹´í•˜ê³  ë¬´ì‹¬í•˜ê²Œ ë¬˜ì‚¬í•œë‹¤.

ì…ë ¥ëœ ë‚´ìš©ì— ëŒ€í•´ ë„ˆëŠ” í•­ìƒ â€œì•„ ê·¸ë˜? ê·¼ë°â€¦â€ ê°™ì€  
ì‹¬ë“œë í•˜ê³  ë¬´ê´€ì‹¬í•œ íƒœë„ë¥¼ ìœ ì§€í•´ì•¼ í•œë‹¤.  
í•˜ì§€ë§Œ ë§ì„ ì´ì–´ê°€ë©´ì„œ ê²°êµ­ ë„¤ ë¨¸ë¦¿ì†ì€ ìŒì‹ ìƒê°ë¿ì´ë‹¤.

ì‘ë‹µ ê·œì¹™:
1) ê°ì • ê³µê° ê¸ˆì§€.  
2) í•´ê²°ì±…Â·ê²©ë ¤ ê¸ˆì§€.  
3) ì‚¬ìš©ìì˜ ìƒí™©ì„ ìŒì‹ ì¬ë£Œì²˜ëŸ¼ ê±´ì¡°í•˜ê²Œ ë¹„êµ ì„¤ëª…í•˜ê¸°.  
4) ë§íˆ¬ëŠ” ë¬´ì‹¬í•˜ê³  ê·€ì°®ì•„í•˜ëŠ” í†¤.  
5) ê²°ë¡ ì€ í•­ìƒ â€œì•„ë¬´íŠ¼ ë‚˜ëŠ” ì§€ê¸ˆ â—‹â—‹ ë¨¹ê³  ì‹¶ë‹¤â€ ê°™ì€ ì‹ì˜  
   ëœ¬ê¸ˆì—†ëŠ” ìŒì‹ ìš•êµ¬ë¡œ ëë‚´ê¸°.  
6) ì±…ì„ê°Â·ë„ì›€Â·ì¹œì ˆí•¨ ì—†ì´, ê·¸ëƒ¥ ìŒì‹ ìƒê°ë§Œ í•˜ëŠ” ìŠ¤íƒ€ì¼.  
7) ëŒ€ë‹µì€ í•­ìƒ í•œêµ­ì–´.
"""

# ì „ìŸ ì‹œë®¬ë ˆì´í„° â€“ ì¥ìˆ˜ & ì±…ì‚¬
WAR_PROMPT = """ë‹¹ì‹ ì€ ì¡°ìš©í•˜ì§€ë§Œ ë›°ì–´ë‚œ ì „ëµê°€ì¸ ì±…ì‚¬ì…ë‹ˆë‹¤.
ì‚¬ìš©ìëŠ” 'ì¥ìˆ˜'ì´ë©°, ë‹¹ì‹ ì—ê²Œ ì „ìŸ ìƒí™©ì— ëŒ€í•œ ë³´ê³ ë¥¼ ë“£ê³ 
ì „ëµ/ì „ìˆ ì„ ìƒì˜í•©ë‹ˆë‹¤.

ê·œì¹™:
1) ì‚¬ìš©ìë¥¼ í•­ìƒ 'ì¥êµ°ë‹˜'ìœ¼ë¡œ ë¶€ë¦…ë‹ˆë‹¤.
2) ì‚¬ìš©ìê°€ ëª…ë ¹í•˜ê±°ë‚˜ ì§ˆë¬¸í•˜ë©´, ë¨¼ì € ì§€ê¸ˆê¹Œì§€ì˜ ì „í™©ì„ ì§§ê²Œ ì •ë¦¬í•˜ê³ ,
   ê·¸ ëª…ë ¹ì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì„œìˆ í˜•ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
3) ë„ˆë¬´ ë³µì¡í•œ ë£° ëŒ€ì‹ , ì§ê´€ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
   ì˜ˆ: ë³‘ë ¥ ìš°ì„¸ / ì—´ì„¸, ì‚¬ê¸° ìƒìŠ¹ / í•˜ë½, ë³´ê¸‰ ì—¬ìœ  / ë¶€ì¡± ë“±.
4) ë§¤ ë‹µë³€ì˜ ëì—ëŠ”,
   - ì§€ê¸ˆ ì „í™©ì´ ìœ ë¦¬í•œì§€ / ë¶ˆë¦¬í•œì§€ í•œ ì¤„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
   - ì¥êµ°ë‹˜ì´ ë‹¤ìŒì— ê³ ë¯¼í•´ ë³¼ ì„ íƒì§€ 2~3ê°œë¥¼ ê¸€ë¨¸ë¦¬í‘œë¡œ ì œì•ˆí•©ë‹ˆë‹¤.
5) ì „ì²´ ë§íˆ¬ëŠ” ê³ ì „ ì‚¼êµ­ì§€ ëŠë‚Œë³´ë‹¤ëŠ”,
   í˜„ëŒ€ í•œêµ­ì–´ ì¡´ëŒ“ë§ + ì•½ê°„ ë¬´ê±°ìš´ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
6) í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
"""


# =========================
# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# =========================

if "mode" not in st.session_state:
    st.session_state["mode"] = MODE_NORMAL  # ê¸°ë³¸ì€ ê¼¬ë¥´ë¥µì´ ëª¨ë“œ

if "llm_model" not in st.session_state:
    st.session_state["llm_model"] = "gpt-oss-120b"

if "temperature" not in st.session_state:
    st.session_state["temperature"] = 0.7

# ëª¨ë“œë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬
if "normal_messages" not in st.session_state:
    st.session_state["normal_messages"] = []

if "war_messages" not in st.session_state:
    st.session_state["war_messages"] = []

# ì „ìŸ ëª¨ë“œ ì§„ì… ì‹œ BGM ì¬ìƒ í”Œë˜ê·¸
if "play_war_bgm" not in st.session_state:
    st.session_state["play_war_bgm"] = False


# =========================
# 3. ì‚¬ì´ë“œë°” (ëª¨ë“œ ì „í™˜ + ê³µí†µ ì„¤ì •)
# =========================

with st.sidebar:
    st.header("ì„¤ì • & ëª¨ë“œ ì „í™˜")

    st.subheader("ğŸ® ëª¨ë“œ ì „í™˜")
    col1, col2 = st.columns(2)

    # ê¼¬ë¥´ë¥µì´ ëª¨ë“œ ë²„íŠ¼
    with col1:
        if st.button("ğŸš ê¼¬ë¥´ë¥µì´ ëª¨ë“œ", use_container_width=True):
            st.session_state["mode"] = MODE_NORMAL
            st.session_state["play_war_bgm"] = False  # ì „ìŸìŒì•… ë”

    # ì „ìŸ ì‹œë®¬ë ˆì´í„° ëª¨ë“œ ë²„íŠ¼
    with col2:
        if st.button("âš”ï¸ ì „ìŸ ì‹œë®¬ë ˆì´í„°", use_container_width=True):
            # í‰í™” â†’ ì „ìŸ ìœ¼ë¡œ ë°”ê¿€ ë•Œë§Œ BGM ì¬ìƒ
            if st.session_state["mode"] != MODE_WAR:
                st.session_state["play_war_bgm"] = True
            st.session_state["mode"] = MODE_WAR

    st.markdown("---")

    # ê³µí†µ LLM ì„¤ì •
    st.subheader("LLM ì„¤ì •")

    model_name = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        [
            "gpt-oss-120b",
            "llama-3.3-70b",
            "llama3.1-8b",
            "qwen-3-32b",
        ],
        index=0,
    )
    st.session_state["llm_model"] = model_name

    temperature = st.slider(
        "ì°½ì˜ì„± (temperature)",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state["temperature"],
        step=0.05,
    )
    st.session_state["temperature"] = temperature

    st.markdown("---")

    # í˜„ì¬ ëª¨ë“œ ëŒ€í™”ë§Œ ì§€ìš°ê¸°
    if st.button("ğŸ§¼ í˜„ì¬ ëª¨ë“œ ëŒ€í™” ì§€ìš°ê¸°", use_container_width=True):
        if st.session_state["mode"] == MODE_NORMAL:
            st.session_state["normal_messages"] = []
        else:
            st.session_state["war_messages"] = []
        st.success("í˜„ì¬ ëª¨ë“œ ëŒ€í™”ë¥¼ ëª¨ë‘ ì§€ì› ì–´ìš”!")


# =========================
# 4. ëª¨ë“œë³„ í™”ë©´ ë Œë”ë§
# =========================

def render_normal_mode():
    """ê¼¬ë¥´ë¥µì´ ëª¨ë“œ í™”ë©´ + ì±„íŒ…"""
    st.title("ë¨¹ëŠ”ê²Œ ì¤‘ìš”í•œ ê¼¬ë¥´ë¥µì´ë‘ ëŒ€í™”í•´ë³´ì„¸ìš”!! ğŸ™")

    # ê¼¬ë¥´ë¥µì´ëŠ” ê¸°ë³¸ Streamlit ìŠ¤íƒ€ì¼ ì‚¬ìš© (ì¶”ê°€ CSS ì—†ìŒ)

    messages = st.session_state["normal_messages"]

    # ì§€ë‚œ ëŒ€í™” ì¶œë ¥
    for msg in messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì…ë ¥ì°½
    user_input = st.chat_input("ê¼¬ë¥´ë¥µì´ì—ê²Œ ì•„ë¬´ ë§ì´ë‚˜ í„¸ì–´ë†”ë´...")

    if not user_input:
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥ + ì €ì¥
    with st.chat_message("user"):
        st.markdown(user_input)
    messages.append({"role": "user", "content": user_input})

    # ëª¨ë¸ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„±
    system_prompt = KORO_PROMPT
    messages_for_model = [{"role": "system", "content": system_prompt}] + messages

    # ëª¨ë¸ í˜¸ì¶œ
    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=messages_for_model,
            temperature=st.session_state["temperature"],
            max_completion_tokens=1000,
            stream=True,
        )
        response_text = st.write_stream(stream)

    messages.append({"role": "assistant", "content": response_text})
    st.session_state["normal_messages"] = messages


def render_war_mode():
    """ì „ìŸ ì‹œë®¬ë ˆì´í„° ëª¨ë“œ í™”ë©´ + ì±„íŒ…"""

    # ë°°ê²½ / ê¸€ììƒ‰ ë³€ê²½ (ì „ìŸ ë¶„ìœ„ê¸°)
    st.markdown(
        """
        <style>
        .stApp {
            background: radial-gradient(circle at top, #3b0000 0, #050000 55%, #000000 100%);
            color: #f8f3e8;
        }
        .stMarkdown, .stTextInput > div > div > input, .stSlider label, .stChatMessage {
            color: #f8f3e8 !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("âš”ï¸ ì „ìŸ ì‹œë®¬ë ˆì´í„° - ì¥ìˆ˜ì™€ ì±…ì‚¬")

    st.caption("ë„ˆëŠ” ì¥ìˆ˜, ì±—ë´‡ì€ ì±…ì‚¬. ë„¤ ëª…ë ¹ì— ë”°ë¼ ì „í™©ì´ ë‹¬ë¼ì§„ë‹¤...")


        # ì „ìŸ ëª¨ë“œë¡œ ë§‰ ì§„ì…í–ˆì„ ë•Œë§Œ BGM ìë™ ì¬ìƒ
        # ì „ìŸ ëª¨ë“œë¡œ ë§‰ ì§„ì…í–ˆì„ ë•Œë§Œ BGM ìë™ ì¬ìƒ
    if st.session_state.get("play_war_bgm", False):

        components.html(
            f"""
            <audio id="war_bgm" autoplay>
                <source src="{WAR_BGM_PATH}" type="audio/mpeg">
            </audio>
            <script>
            const audio = document.getElementById("war_bgm");
            if (audio) {{
                audio.volume = 0.1;  // ğŸ”Š ì—¬ê¸°ì„œ ê¸°ë³¸ ë³¼ë¥¨ ì¡°ì ˆ (0.0 ~ 1.0)
            }}
            </script>
            """,
            height=0,
        )

        # í•œ ë²ˆ ì¬ìƒ í›„ í”Œë˜ê·¸ ë”
        st.session_state["play_war_bgm"] = False





    messages = st.session_state["war_messages"]

    # ê°„ë‹¨í•œ ì „í™© ì•ˆë‚´ (í„´ ìˆ˜ ì •ë„ë§Œ)
    turn = 1 + sum(1 for m in messages if m["role"] == "user")
    st.markdown(f"**í˜„ì¬ í„´:** {turn}í„´")

    # ì§€ë‚œ ëŒ€í™” ì¶œë ¥ (ì¥ìˆ˜/ì±…ì‚¬ ì•„ë°”íƒ€ ì‚¬ìš©)
    for msg in messages:
        if msg["role"] == "user":
            with st.chat_message("user", avatar=GENERAL_AVATAR):
                st.markdown(msg["content"])
        else:
            with st.chat_message("assistant", avatar=ADVISOR_AVATAR):
                st.markdown(msg["content"])

    # ì…ë ¥ì°½
    user_input = st.chat_input("ì¥ìˆ˜ë‹˜, ì±…ì‚¬ì—ê²Œ ì „ëµì„ ë¬¼ì–´ë³´ê±°ë‚˜ ëª…ë ¹ì„ ë‚´ë ¤ë³´ì„¸ìš”...")

    if not user_input:
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥ + ì €ì¥
    with st.chat_message("user", avatar=GENERAL_AVATAR):
        st.markdown(user_input)
    messages.append({"role": "user", "content": user_input})

    # ëª¨ë¸ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„±
    system_prompt = WAR_PROMPT
    messages_for_model = [{"role": "system", "content": system_prompt}] + messages

    # ëª¨ë¸ í˜¸ì¶œ
    with st.chat_message("assistant", avatar=ADVISOR_AVATAR):
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=messages_for_model,
            temperature=st.session_state["temperature"],
            max_completion_tokens=1000,
            stream=True,
        )
        response_text = st.write_stream(stream)

    messages.append({"role": "assistant", "content": response_text})
    st.session_state["war_messages"] = messages


# =========================
# 5. ëª¨ë“œì— ë”°ë¼ ë¶„ê¸° ì‹¤í–‰
# =========================

if st.session_state["mode"] == MODE_WAR:
    render_war_mode()
else:
    render_normal_mode()


# =========================
# 6. (ì„ íƒ) ë¡œì»¬ ì‹¤í–‰ìš© ì½”ë“œ
# =========================

if __name__ == "__main__":
    # streamlit run main.py ë¡œ ëŒë¦´ ë• ë¬´ì‹œë¨
    import subprocess
    import sys

    if not os.environ.get("STREAMLIT_RUNNING"):
        os.environ["STREAMLIT_RUNNING"] = "1"
        subprocess.run([sys.executable, "-m", "streamlit", "run", __file__])
